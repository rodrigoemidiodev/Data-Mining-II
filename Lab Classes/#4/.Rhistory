install.packages("tidyverse")
prices
prices
prices <- c(Portugal=10.3, Spain=10.6, Italy=11.5, France=12.3, Germany=9.9, Greece=9.3, UK=11.4, Finland=10.9, Belgium=12.1, Austria=9.1)
prices
prices_with_vat <- 1.23*prices
prices_with_vat
prices[prices > 10]
prices[prices > mean(prices)]
prices[prices > 10 & prices < 11]
raised_prices <- 1.1 * prices
raised_prices
lower_prices <- prices[prices > mean(prices)] * 0,975
lower_prices <- prices[prices > mean(prices)] * 0.975
lower_prices
euro2currency <- function(value, currency) value * exchange_rate["currency"]
euro2currency(3, usd)
euro2currency(3, "usd")
exchange_rate <- c(usd=1.0458, gbp=0.8276, jpy=156.11, chf=0.9389, huf=403.0416)
euro2currency <- function(value, currency) value * exchange_rate["currency"]
euro2currency(2, "usd")
euro2currency(2, usd)
euro2currency <- function(value, currency) value * exchange_rate[currency]
euro2currency(2, usd)
euro2currency(2, "usd")
amounts <- [50, 100, 150]
euro2currency(amounts, "chf")
amounts <- [50, 100, 150]
amounts <- c(50, 100, 150)
euro2currency(amounts, "chf")
help(Boston, package='MASS')
data(Boston, package='MASS')
prices <- data(Boston, package='MASS')
prices
packages.install('MASS')
install.packages('MASS')
prices <- data(Boston, package='MASS')
prices
library(MASS)
data(Boston)
str(Boston)
data(Boston, package = 'MASS')
str(Boston)
prices <- data(Boston, package = 'MASS')
str(prices)
str(Boston)
data(Boston, package = 'MASS')
subset(Boston, medv > 45)
subset(Boston, rm > 8, c(nox, tax))
subset(Boston, medv > 10 & medv < 15)
subset(Boston, medv >= 10 & medv <= 15)
subset(Boston, rm > 6, c(mean(crim)))
mean(Boston$crim(Boston$rm > 6))
mean(Boston$crim[Boston$rm > 6])
install.packages("dplyr")
library(arules)
library(arulesViz)
install.packages('arulesViz')
library(arulesViz)
data(Groceries)
Groceries
class(Groceries)
# Get information on the dataset
summary(Groceries)
# Get the size of the dataset
size(Groceries)
# Get the size of the dataset
head(size(Groceries))
# Inspect the dataset and its type
Groceries
class(Groceries)
# Get information on the dataset
summary(Groceries)
# Get the size of the dataset
head(size(Groceries))
# Get the first five transactions
inspect(Groceries[1:5])
size(Groceries)
# Check if there are duplicated transactions
unique(Groceries)
# Check if there are duplicated transactions
length(which(unique(Groceries)))
# Check if there are duplicated transactions
length(which(duplicated(Groceries)))
# See the relative frequency of each item
head(itemFrequency(Groceries))
# Plot the top 5 more frequent items
head(itemFrequencyPlot(Groceries))
# Plot the top 5 more frequent items
itemFrequencyPlot(Groceries, topN = 5)
# Plot the items that have a support value of at least 0.1
itemFrequencyPlot(Groceries, support = 0.1)
# Obtain the frequent itemsets for a minimum support of 0.01
itemsets <- apriori(Groceries, parameter = list(supp = 0.1, target = "frequent itemsets"))
class(itemsets)
class(itemsets)
class(Groceries)
# Inspect the 5 most frequent itemsets
inspect(itemsets[1:5])
# Inspect the 5 most frequent itemsets
inspect(sort(itemsets)[1:5])
# Select the subset of closed frequent itemsets and the subset of maximal frequent itemsets from the frequent itemsets obtained
itemsets[is.closed(itemsets)]
itemsets[is.maximal(itemsets)]
# Generate the rules from the dataset using apriori
rules <- apriori(Groceries)
class(rules)
# Generate new rules with updated minimum support and confidence
rules_new <- apriori(Groceries, parameter = list(supp = 0.1, conf = 0.3, minlen = 2, target = "rules"))
# Generate new rules with updated minimum support and confidence
rules_new <- apriori(Groceries, parameter = list(supp = 0.1, conf = 0.3)
# Generate new rules with updated minimum support and confidence
rules_new <- apriori(Groceries, parameter = list(supp = 0.1, conf = 0.3))
# Generate new rules with updated minimum support and confidence
rules_new <- apriori(Groceries, parameter = list(supp = 0.1, conf = 0.3))
# Generate the rules from the dataset using apriori and check its class
rules <- apriori(Groceries)
# Generate new rules with updated minimum support and confidence
rules_new <- apriori(Groceries, parameter = list(supp = 0.1, conf = 0.3))
# Obtain the rules with minsup = 0.01 and minconf = 0.25
rules <- apriori(Groceries, parameter = list(supp = 0.01, conf = 0.25))
summary(rules)
quality(rules)
quality(sort(rules))
quality(rules[1:5])
plot(rules[1:5])
inspect(rules[1:5])
# Select the rules with a lift value above 2
rules.sub <- subset(rules, subset = lift > 2)
inspect(rules.sub[1:5])
# Select the rules that have lift value above 2 and the items "whole milk" or "yogurt" on the consequent
rules.sub <- subset(rules, subset = rhs %in% c("yogurt", "whole milk") & lift > 2)
rules.sort <- sort(rules.sub, by "lift")
rules.sort <- sort(rules.sub, by = "lift")
inspect(rules.sort[1:5])
plot(rules.sub)
plot(rules.sub, method = "graph")
# Inspect how many times each page was visited
page_visits <- table(df$PAGE)
# Set the working directory dinamically
wd <- readline(prompt = "Enter the path of your working directory: ")
setwd(wd)
# Read the csv file into a data frame
df <- read.csv("log.csv")
# Inspect how many times each page was visited
page_visits <- table(df$PAGE)
print(page_visits)
# Sort the pages by decreasing number of visits
sorted_pages <- sort(page_visits, decreasing = TRUE)
print(sorted_pages)
# Obtain the top 3 pages for recommendation
top_3_pages <- names(sorted_pages)[1:3]
print(top_3_pages)
